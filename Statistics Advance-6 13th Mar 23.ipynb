{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4535fd1-baff-4723-9403-6ab845a93cfa",
   "metadata": {},
   "source": [
    "**Q1.** Explain the assumptions required to use ANOVA and provide examples of violations that could impact the validity of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f95390-c9bb-4bf9-9e2e-d64edf25a328",
   "metadata": {},
   "source": [
    "**Answer 1** -\n",
    "\n",
    "ANOVA (Analysis of Variance) is a statistical method used to compare the means of three or more groups on a continuous outcome variable. The following are the assumptions required to use ANOVA:\n",
    "\n",
    "1. Independence: The observations within each group should be independent of each other. This means that the value of one observation should not be influenced by the value of another observation.\n",
    "\n",
    "2. Normality: The outcome variable should follow a normal distribution within each group. This means that the distribution of the outcome variable should be approximately bell-shaped and symmetric.\n",
    "\n",
    "3. Homogeneity of variance: The variance of the outcome variable should be approximately equal across all groups. This means that the variability of the outcome variable should be similar in each group.\n",
    "\n",
    "Violations of these assumptions could impact the validity of the results of ANOVA. \n",
    "\n",
    "For example:\n",
    "\n",
    "1. Violation of independence: This can occur when observations within a group are correlated, which can lead to biased estimates of group means and wider confidence intervals. For example, in a study of the effect of teaching style on student grades, if students are assigned to classes based on their ability level, there may be correlation among students in the same class.\n",
    "\n",
    "2. Violation of normality: This can occur when the outcome variable is not normally distributed within a group, which can affect the accuracy of the p-value and confidence interval. For example, in a study of the effect of a drug on blood pressure, if the blood pressure measurements are skewed, ANOVA may not be appropriate.\n",
    "\n",
    "3. Violation of homogeneity of variance: This can occur when the variance of the outcome variable is not equal across groups, which can lead to incorrect conclusions about group differences. For example, in a study of the effect of fertilizer on crop yield, if the variance of the yield is higher for one type of fertilizer, ANOVA may not be appropriate.\n",
    "\n",
    "In summary, ANOVA requires the assumptions of independence, normality, and homogeneity of variance. Violations of these assumptions can impact the validity of the results. It is important to check for these violations and, if present, consider alternative statistical methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fa2d25-3583-4688-879b-68a0566530c3",
   "metadata": {},
   "source": [
    "**Q2.** What are the three types of ANOVA, and in what situations would each be used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facee9af-3e38-4c7a-821c-1525902f2afc",
   "metadata": {},
   "source": [
    "**Answer** -\n",
    "\n",
    "The three types of ANOVA are:\n",
    "\n",
    "1. One-way ANOVA: This is used when we want to compare the means of three or more groups with one independent variable. For example, we might want to compare the mean test scores of students who have studied for different durations of time (e.g., 1 hour, 2 hours, 3 hours).\n",
    "\n",
    "2. Two-way ANOVA: This is used when we want to compare the means of three or more groups with two independent variables. For example, we might want to compare the mean test scores of students who have studied for different durations of time (e.g., 1 hour, 2 hours, 3 hours) and who come from different schools (e.g., School A, School B).\n",
    "\n",
    "3. Three-way ANOVA: This is used when we want to compare the means of three or more groups with three independent variables. For example, we might want to compare the mean test scores of students who have studied for different durations of time (e.g., 1 hour, 2 hours, 3 hours), who come from different schools (e.g., School A, School B), and who have different ages (e.g., 10 years old, 11 years old, 12 years old).\n",
    "\n",
    "In summary, we use one-way ANOVA when we have one independent variable, two-way ANOVA when we have two independent variables, and three-way ANOVA when we have three independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3223293-d957-4f34-9d01-1b6debabf9d7",
   "metadata": {},
   "source": [
    "**Q3.** What is the partitioning of variance in ANOVA, and why is it important to understand this concept?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671857a5-af78-4899-a710-bc5933426053",
   "metadata": {},
   "source": [
    "**Answer 3** \n",
    "\n",
    "The partitioning of variance in ANOVA refers to the process of dividing the total variance observed in a dataset into two or more components. The components are then used to test hypotheses about the effects of different factors on the dependent variable. \n",
    "\n",
    "The total variance in a dataset is the sum of the variance within groups (the variability within each group of the independent variable) and the variance between groups (the variability between the different groups of the independent variable). \n",
    "\n",
    "By partitioning the variance, ANOVA helps to determine the relative contributions of different sources of variability to the observed differences in the means of the groups. This can be useful in determining the factors that are most important in explaining the variability in the data, and in identifying potential sources of error or bias in the analysis.\n",
    "\n",
    "Understanding the concept of partitioning of variance is important because it provides a framework for analyzing the results of an ANOVA and interpreting the significance of different factors on the dependent variable. Additionally, it helps to identify which factors may be contributing more to the observed differences in means, and can be used to guide further investigation or analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf0b77d-c61d-486f-9530-0649d753821f",
   "metadata": {},
   "source": [
    "**Q4.** How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual\n",
    "sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7ed192-b1bb-42da-9a2c-77a97f66062d",
   "metadata": {},
   "source": [
    "**Answer -**\n",
    "\n",
    "In a one-way ANOVA, the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) can be calculated using Python. Here's how:\n",
    "\n",
    "Assuming you have imported the necessary libraries (numpy and pandas) and read in your data as a dataframe named \"df\", you can calculate SST, SSE, and SSR as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6cbb81a-b955-43bc-920e-c55589162638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SST: 64.16666666666669\n",
      "SSE: 18.333333333333332\n",
      "SSR: 45.83333333333336\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Create a pandas dataframe with a dependent variable and an independent variable\n",
    "dependent_variable = np.array([2, 4, 5, 3, 6, 7, 8, 9, 10, 11])\n",
    "group_variable = np.array(['A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C', 'C'])\n",
    "df = pd.DataFrame({'dependent_variable': dependent_variable, 'group_variable': group_variable})\n",
    "\n",
    "# Define the ANOVA model\n",
    "model = ols('dependent_variable ~ group_variable', data=df).fit()\n",
    "\n",
    "# Calculate the total sum of squares (SST)\n",
    "sst = sm.stats.anova_lm(model, typ=1)['sum_sq'][0]\n",
    "\n",
    "# Calculate the explained sum of squares (SSE)\n",
    "sse = sm.stats.anova_lm(model, typ=1)['sum_sq'][1]\n",
    "\n",
    "# Calculate the residual sum of squares (SSR)\n",
    "ssr = sst - sse\n",
    "\n",
    "print('SST:', sst)\n",
    "print('SSE:', sse)\n",
    "print('SSR:', ssr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad81b22b-fdb7-473a-b994-9ed99ff1056e",
   "metadata": {},
   "source": [
    "In this code, \"dependent_variable\" refers to the variable you are measuring (the \"y\" variable), and \"independent_variable\" refers to the factor you are testing (the \"x\" variable). The code calculates the grand mean of the dependent variable, and then calculates SST as the sum of the squared deviations of each observation from the grand mean. SSE is calculated as the sum of the squared deviations of each group mean from the grand mean, weighted by the size of each group. Finally, SSR is calculated as the sum of the squared deviations of each observation from its group mean. The code also calculates the degrees of freedom for each component, which are used in further ANOVA calculations.\n",
    "\n",
    "Note that this code assumes that the data are balanced (i.e., each group has the same number of observations) and that the variances of the groups are equal. If these assumptions are violated, more complex ANOVA models may be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7e468b-ce7d-439a-8ebf-5c1583d2cc31",
   "metadata": {},
   "source": [
    "**Q5.** In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c5c590-45e7-4d94-b4d3-dc8af06fe715",
   "metadata": {},
   "source": [
    "**Answer -** \n",
    "\n",
    "In a two-way ANOVA, the main effects of each factor and the interaction effect between the factors can be calculated using the statsmodels library in Python.\n",
    "\n",
    "To calculate the main effects, we can use the ols function to fit a linear model with the response variable and each factor separately. For example, if we have two factors A and B, we can calculate the main effect of A as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5918d315-21c1-492a-9fbe-8bcc62229aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main effect of independent variable 1: 47.99999999999992\n",
      "Main effect of independent variable 2: 3.155443620884047e-29\n",
      "Interaction effect: 192.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Create a pandas dataframe with two independent variables and a dependent variable\n",
    "independent_variable_1 = np.array(['A', 'B', 'C', 'A', 'B', 'C', 'A', 'B', 'C', 'A', 'B', 'C'])\n",
    "independent_variable_2 = np.array(['X', 'X', 'X', 'Y', 'Y', 'Y', 'X', 'X', 'X', 'Y', 'Y', 'Y'])\n",
    "dependent_variable = np.array([10, 12, 8, 14, 16, 12, 18, 20, 16, 22, 24, 20])\n",
    "df = pd.DataFrame({'independent_variable_1': independent_variable_1, 'independent_variable_2': independent_variable_2, 'dependent_variable': dependent_variable})\n",
    "\n",
    "\n",
    "# Define the ANOVA model with interaction\n",
    "model_interaction = ols('dependent_variable ~ independent_variable_1 * independent_variable_2', data=df).fit()\n",
    "\n",
    "# Calculate the main effects and interaction effects\n",
    "main_effect_1 = sm.stats.anova_lm(model_interaction, typ=1)['sum_sq'][1]\n",
    "main_effect_2 = sm.stats.anova_lm(model_interaction, typ=1)['sum_sq'][2]\n",
    "interaction_effect = sm.stats.anova_lm(model_interaction, typ=1)['sum_sq'][3]\n",
    "\n",
    "print('Main effect of independent variable 1:', main_effect_1)\n",
    "print('Main effect of independent variable 2:', main_effect_2)\n",
    "print('Interaction effect:', interaction_effect)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f41312-0f97-4133-b805-a362c9e10528",
   "metadata": {},
   "source": [
    "**Q6.** Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02.\n",
    "What can you conclude about the differences between the groups, and how would you interpret these\n",
    "results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49ab125-6faf-4874-bdc0-b0aea5dbdc5f",
   "metadata": {},
   "source": [
    "**Answer 6-**\n",
    "\n",
    "If the F-statistic of 5.23 and a p-value of 0.02 was obtained in a one-way ANOVA, it means that there is evidence of significant differences between the groups being compared. Specifically, it means that the variation in the sample means across the groups is greater than what would be expected by chance alone.\n",
    "\n",
    "The p-value of 0.02 indicates that the probability of observing an F-statistic as extreme as the one obtained, assuming there is no difference between the groups, is only 0.02. This is below the commonly used significance level of 0.05, suggesting that the null hypothesis (i.e., there is no difference between the groups) should be rejected in favor of the alternative hypothesis (i.e., there is at least one group that is different from the others).\n",
    "\n",
    "The effect size can also be calculated to better understand the magnitude of the differences between the groups. For example, one commonly used effect size measure is eta-squared (η2), which is the proportion of the total variance in the dependent variable that is explained by the group membership. The formula for calculating eta-squared is:\n",
    "\n",
    "η2 = SSE / SST\n",
    "\n",
    "where SSE is the sum of squared errors and SST is the total sum of squares.\n",
    "\n",
    "If eta-squared was found to be 0.15, for example, this would mean that 15% of the variance in the dependent variable can be explained by the group membership."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553f3263-102e-4cfa-b534-8217c9edc714",
   "metadata": {},
   "source": [
    "**Q7.** In a repeated measures ANOVA, how would you handle missing data, and what are the potential\n",
    "consequences of using different methods to handle missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f306e87-2366-4d3a-9b83-5dafa9167969",
   "metadata": {},
   "source": [
    "**Answer 7-** In a repeated measures ANOVA, missing data can be handled in several ways, such as:\n",
    "\n",
    "1. Pairwise deletion: This involves deleting cases that have missing data on one or more variables. This method can lead to biased estimates if the missing data are not missing completely at random (MCAR).\n",
    "\n",
    "2. Listwise deletion: This involves deleting cases that have missing data on any variable in the analysis. This method can lead to a loss of power if there are a large number of missing cases.\n",
    "\n",
    "3. Imputation: This involves replacing missing values with estimated values. Imputation methods can be either single imputation or multiple imputation. Single imputation methods include mean imputation, median imputation, and regression imputation. Multiple imputation involves creating multiple imputed datasets based on the observed data and using these datasets to estimate the parameters of interest. \n",
    "\n",
    "The consequences of using different methods to handle missing data in a repeated measures ANOVA depend on the extent and pattern of missing data and the method used for handling missing data. If the missing data are MCAR, all methods will yield unbiased estimates. However, if the missing data are not MCAR, then pairwise or listwise deletion can lead to biased estimates and reduced power. Imputation methods can also lead to biased estimates if the imputation model is misspecified or if the assumptions underlying the imputation method are violated.\n",
    "\n",
    "It is important to carefully consider the pattern and extent of missing data in a repeated measures ANOVA and to use appropriate methods for handling missing data to ensure valid and reliable results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f81955-6c29-451f-94ef-b8d7dcb8eb3c",
   "metadata": {},
   "source": [
    "Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide an example of a situation where a post-hoc test might be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a005c76d-dc18-466a-ae2b-751827796087",
   "metadata": {},
   "source": [
    "Answer - Post-hoc tests are used after ANOVA to determine which groups differ significantly from each other. Some common post-hoc tests include Tukey's Honestly Significant Difference (HSD) test, Bonferroni correction, Scheffe's method, and Dunnett's test.\n",
    "\n",
    "Tukey's HSD test is used when all pairwise comparisons between groups are of interest, and it is generally the most powerful test. Bonferroni correction is more conservative and is used when multiple comparisons are made. Scheffe's method is used when the sample sizes are unequal and the variances are unequal. Dunnett's test is used when there is one control group and multiple treatment groups.\n",
    "\n",
    "For example, suppose a researcher conducts a study to determine if there is a difference in the mean test scores between three different teaching methods. After conducting an ANOVA, the researcher finds that there is a significant difference between the groups. To determine which groups differ significantly from each other, the researcher can conduct a post-hoc test such as Tukey's HSD test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103c21b8-06b7-4e20-a4d9-7946a754ad24",
   "metadata": {},
   "source": [
    "**Q9.** A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from 50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python to determine if there are any significant differences between the mean weight loss of the three diets.\n",
    "\n",
    "Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41dd8b8c-7c63-4bd7-b0fa-127c1f92c4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 57.06379442059458\n",
      "p-value: 4.5619061215783055e-19\n",
      "We reject the null hypothesis.\n",
      "Conclusion : The mean weight loss is different for at least one diet.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Generate simulated data assuming normal distribution with same variance\n",
    "np.random.seed(1)\n",
    "diet_A = np.random.normal(5, 1, 50)\n",
    "diet_B = np.random.normal(4, 1, 50)\n",
    "diet_C = np.random.normal(3, 1, 50)\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "# Set significance level\n",
    "alpha = 0.05\n",
    "\n",
    "# Null hypothesis: The mean weight loss is the same for all three diets.\n",
    "# Alternative hypothesis: The mean weight loss is different for at least one diet.\n",
    "null_hypothesis = \"The mean weight loss is the same for all three diets.\"\n",
    "alternate_hypothesis = \"The mean weight loss is different for at least one diet.\"\n",
    "\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "if p_value < alpha:\n",
    "    print(\"We reject the null hypothesis.\")\n",
    "    print(f\"Conclusion : {alternate_hypothesis}\")\n",
    "else:\n",
    "    print(\"We fail to reject the null hypothesis.\")\n",
    "    print(f\"Conclusion : {null_hypothesis}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604f4d6f-bb0b-4155-9399-d4532dd4b01d",
   "metadata": {},
   "source": [
    "## Performing Tukey's test for mean difference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efaae348-feb4-4ffd-81d3-78a5f70d1db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05\n",
      "===================================================\n",
      "group1 group2 meandiff p-adj  lower   upper  reject\n",
      "---------------------------------------------------\n",
      "     A      B  -0.8278   0.0 -1.2477 -0.4079   True\n",
      "     A      C  -1.8898   0.0 -2.3097 -1.4699   True\n",
      "     B      C   -1.062   0.0 -1.4819 -0.6421   True\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "#create DataFrame to hold data\n",
    "df = pd.DataFrame({'weight_loss': list(diet_A) + list(diet_B) + list(diet_C),\n",
    "                   'group': np.repeat(['A', 'B', 'C'], repeats=50)})\n",
    "\n",
    "# perform Tukey's test\n",
    "tukey = pairwise_tukeyhsd(endog=df['weight_loss'],\n",
    "                          groups=df['group'],\n",
    "                          alpha=0.05)\n",
    "\n",
    "# Print results\n",
    "print(tukey)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2448316a-3f60-4173-82d2-48a7b11d63d7",
   "metadata": {},
   "source": [
    "## Above interpretation means all three means are different reject value is True for all of 3\n",
    "1. Mean Difference between diet_A and diet_B is -0.8278\n",
    "2. Mean Difference between diet_A and diet_C is -1.8898\n",
    "3. Mean Difference between diet_A and diet_C is -1.062"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abb4f80-511f-41cb-b451-4f895bad0892",
   "metadata": {},
   "source": [
    "**Q10.** A company wants to know if there are any significant differences in the average time it takes to complete a task using three different software programs: Program A, Program B, and Program C. They randomly assign 30 employees to one of the programs and record the time it takes each employee to complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or interaction effects between the software programs and employee experience level (novice vs.experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ce85e08-f4fb-42cf-9870-2a361c933318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated Data example :\n",
      "  Software Experience       Time\n",
      "0        A     Novice  12.828739\n",
      "1        A     Novice  16.994691\n",
      "2        A     Novice  15.565957\n",
      "3        A     Novice  11.987411\n",
      "4        A     Novice  13.842799\n",
      "\n",
      "======================================================================================\n",
      "\n",
      "                             df      sum_sq     mean_sq          F  \\\n",
      "C(Software)                 2.0  204.881181  102.440590  18.135666   \n",
      "C(Experience)               1.0  165.079097  165.079097  29.224933   \n",
      "C(Software):C(Experience)   2.0   17.481552    8.740776   1.547431   \n",
      "Residual                   56.0  316.319953    5.648571        NaN   \n",
      "\n",
      "                                 PR(>F)  \n",
      "C(Software)                8.460472e-07  \n",
      "C(Experience)              1.375177e-06  \n",
      "C(Software):C(Experience)  2.217544e-01  \n",
      "Residual                            NaN  \n",
      "\n",
      "\n",
      "Conclusion: There is a significant main effect of software.\n",
      "Conclusion: There is a significant main effect of experience.\n",
      "Conclusion: There is no significant interaction effect between software and experience.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Setting random seed for reproducibility\n",
    "np.random.seed(123)\n",
    "\n",
    "# Generating 2 random time samples for novice and expert\n",
    "time_novice = np.random.normal(loc=15, scale=2, size=30)\n",
    "time_expert = np.random.normal(loc=10, scale=2, size=30)\n",
    "\n",
    "# Generate simulated data\n",
    "data = pd.DataFrame({\n",
    "    'Software': ['A']*20 + ['B']*20 + ['C']*20,\n",
    "    'Experience': ['Novice']*30 + ['Experienced']*30,\n",
    "    'Time': list(time_novice)+list(time_expert)\n",
    "})\n",
    "\n",
    "# Print the simulated data head \n",
    "print('Simulated Data example :')\n",
    "print(data.head())\n",
    "\n",
    "print('\\n======================================================================================\\n')\n",
    "\n",
    "# Fit the two-way ANOVA model\n",
    "model = ols('Time ~ C(Software) + C(Experience) + C(Software):C(Experience)', data=data).fit()\n",
    "table = sm.stats.anova_lm(model, typ=1)\n",
    "\n",
    "# Set significance level\n",
    "alpha = 0.05\n",
    "\n",
    "# Main effects and interaction effect\n",
    "print(table)\n",
    "print('\\n')\n",
    "if table['PR(>F)'][0] < alpha:\n",
    "    print(\"Conclusion: There is a significant main effect of software.\")\n",
    "else:\n",
    "    print(\"Conclusion: There is no significant main effect of software.\")\n",
    "\n",
    "if table['PR(>F)'][1] < alpha:\n",
    "    print(\"Conclusion: There is a significant main effect of experience.\")\n",
    "else:\n",
    "    print(\"Conclusion: There is no significant main effect of experience.\")\n",
    "\n",
    "if table['PR(>F)'][2] < alpha:\n",
    "    print(\"Conclusion: There is a significant interaction effect between software and experience.\")\n",
    "else:\n",
    "    print(\"Conclusion: There is no significant interaction effect between software and experience.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde98ea4-7ad6-4c3b-8d35-d4f390f34b11",
   "metadata": {},
   "source": [
    "## Here are the interpretations of the three conclusions:\n",
    "1. \"There is a significant main effect of software\": This means that the software programs used by the employees have a significant impact on the outcome variable (e.g., completion time), independent of the experience level of the employees. This suggests that the choice of software program is an important factor that should be considered carefully when completing this task.\n",
    "\n",
    "2. \"There is a significant main effect of experience\": This means that the experience level of the employees has a significant impact on the outcome variable, independent of the software program used. Specifically, this suggests that experienced employees may complete the task faster than novices, or vice versa. This finding can be helpful for the company to identify the best employees for a given task and to provide appropriate training for new employees.\n",
    "\n",
    "3. \"There is NO significant interaction effect between software and experience\": This means that the effect of software on the outcome variable does not depend on the experience level of the employees, and vice versa. This suggests that the software programs perform similarly for both novices and experienced employees. This finding can be helpful for the company to decide which software program to use, as they do not need to consider the experience level of the employees when making the choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1158b81-aee9-4203-bd70-42946c79291e",
   "metadata": {},
   "source": [
    "Q11. An educational researcher is interested in whether a new teaching method improves student test scores. They randomly assign 100 students to either the control group (traditional teaching method) or the experimental group (new teaching method) and administer a test at the end of the semester. Conduct a\n",
    "two-sample t-test using Python to determine if there are any significant differences in test scores between the two groups. If the results are significant, follow up with a post-hoc test to determine which group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca76794f-c83c-4b33-8aa4-440421aa225e",
   "metadata": {},
   "source": [
    "## Two Sample t-test, alpha = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a63dd69b-17fd-4628-8e9f-46a45c880593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated data for test_scores:\n",
      "   test_score    group\n",
      "0   70.079124  control\n",
      "1   70.780965  control\n",
      "2   68.814563  control\n",
      "3   69.387097  control\n",
      "4   66.185102  control\n",
      "\n",
      "===============================\n",
      "\n",
      "t-statistic: -28.5074, p-value: 3.096206271894725e-49\n",
      "\n",
      "\n",
      "Reject the Null Hypothesis\n",
      "Conclusion : There is SIGNIFICANT difference in test scores between the control and experimental groups.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Setting numpy random seed\n",
    "np.random.seed(45)\n",
    "\n",
    "# Generating normal test scores with same variance for both control groups\n",
    "test_score_control = np.random.normal(loc=70, scale=3, size=50)\n",
    "test_score_experimental = np.random.normal(loc=85, scale=3, size=50)\n",
    "\n",
    "# Creating the dataframe\n",
    "df = pd.DataFrame({'test_score':list(test_score_control)+list(test_score_experimental),\n",
    "                   'group':['control']*50 + ['experimental']*50})\n",
    "\n",
    "# printing the sample dataframe\n",
    "print('Simulated data for test_scores:')\n",
    "print(df.head())\n",
    "print('\\n===============================\\n')\n",
    "\n",
    "null_hypothesis = \"There is NO difference in test scores between the control and experimental groups.\"\n",
    "alt_hypothesis = \"There is SIGNIFICANT difference in test scores between the control and experimental groups.\"\n",
    "\n",
    "# Conduct the two-sample t-test\n",
    "control_scores = df[df['group'] == 'control']['test_score']\n",
    "experimental_scores = df[df['group'] == 'experimental']['test_score']\n",
    "t_stat, p_val = ttest_ind(control_scores, experimental_scores, equal_var=True)\n",
    "print(f\"t-statistic: {t_stat:.4f}, p-value: {p_val}\")\n",
    "print('\\n')\n",
    "\n",
    "# Significance value \n",
    "alpha = 0.05\n",
    "if p_val<alpha:\n",
    "    print('Reject the Null Hypothesis')\n",
    "    print(f'Conclusion : {alt_hypothesis}')\n",
    "else:\n",
    "    print('Failed to reject the Null Hypothesis')\n",
    "    print(f'Conclusion : {null_hypothesis}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430fe792-2af9-486e-8413-1c8ecd71e8f9",
   "metadata": {},
   "source": [
    "## 2. Tukey's HSD test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6e1eff1-1457-4092-86b9-a681884e0378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Multiple Comparison of Means - Tukey HSD, FWER=0.05    \n",
      "==========================================================\n",
      " group1    group2    meandiff p-adj  lower   upper  reject\n",
      "----------------------------------------------------------\n",
      "control experimental  15.8829   0.0 14.7773 16.9886   True\n",
      "----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Conduct post-hoc Tukey's test\n",
    "tukey_results = pairwise_tukeyhsd(df['test_score'], df['group'], 0.05)\n",
    "print(tukey_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5191336-cc83-4be2-a6b2-58450cec8c6b",
   "metadata": {},
   "source": [
    "## Tukey's Results Interpretation\n",
    "\n",
    "1. Reject = True suggests that there is significant difference in both control and Experimental groups also p-adj is almost 0.\n",
    "\n",
    "2. Experimental group has increased the performance of test scores of students by mean of 15.88 approximately\n",
    "\n",
    "3. Mean score improved by Experimental method is (14.78,16.99) with 95% confidence level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473bb563-836c-40ec-9222-0bce706af9a6",
   "metadata": {},
   "source": [
    "Q12. A researcher wants to know if there are any significant differences in the average daily sales of three\n",
    "retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store\n",
    "on those days. Conduct a repeated measures ANOVA using Python to determine if there are any significant differences in sales between the three stores. If the results are significant, follow up with a post-hoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5aed19-4b0c-4c1f-b79a-46525dc8d18c",
   "metadata": {},
   "source": [
    "## Answer - \n",
    "\n",
    "1. Assumed significance value of 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "568ed243-ca0f-4d0e-8b67-d82a40a0ad5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated data top 5 rows : \n",
      "   Day    Store        Sales\n",
      "0    0  Store A   933.187150\n",
      "1    1  Store A   950.179048\n",
      "2    2  Store A  1061.857582\n",
      "3    3  Store A  1056.869225\n",
      "4    4  Store A  1135.050948\n",
      "\n",
      "================================================\n",
      "\n",
      "               Anova\n",
      "===================================\n",
      "      F Value Num DF  Den DF Pr > F\n",
      "-----------------------------------\n",
      "Store 51.5040 2.0000 58.0000 0.0000\n",
      "===================================\n",
      "\n",
      "Reject the Null Hypothesis : Atleast one of the group has different mean.\n",
      "\n",
      "Tukey HSD posthoc test:\n",
      "    Multiple Comparison of Means - Tukey HSD, FWER=0.05    \n",
      "===========================================================\n",
      " group1  group2  meandiff p-adj    lower     upper   reject\n",
      "-----------------------------------------------------------\n",
      "Store A Store B   21.2439 0.6945   -40.881   83.3688  False\n",
      "Store A Store C -207.8078    0.0 -269.9328 -145.6829   True\n",
      "Store B Store C -229.0517    0.0 -291.1766 -166.9268   True\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# set random seed for reproducibility\n",
    "np.random.seed(456)\n",
    "\n",
    "# generate sales data for Store A, B, and C\n",
    "sales_a = np.random.normal(loc=1000, scale=100, size=(30,))\n",
    "sales_b = np.random.normal(loc=1050, scale=150, size=(30,))\n",
    "sales_c = np.random.normal(loc=800, scale=80, size=(30,))\n",
    "\n",
    "# create a DataFrame to store the sales data\n",
    "sales_df = pd.DataFrame({'Store A': sales_a, 'Store B': sales_b, 'Store C': sales_c})\n",
    "\n",
    "# reshape the DataFrame for repeated measures ANOVA\n",
    "sales_melted = pd.melt(sales_df.reset_index(), id_vars=['index'], value_vars=['Store A', 'Store B', 'Store C'])\n",
    "sales_melted.columns = ['Day', 'Store', 'Sales']\n",
    "\n",
    "# Printing top 5 rows of generated data\n",
    "print('Generated data top 5 rows : ')\n",
    "print(sales_melted.head())\n",
    "\n",
    "print('\\n================================================\\n')\n",
    "\n",
    "# perform repeated measures ANOVA\n",
    "rm_anova = AnovaRM(sales_melted, 'Sales', 'Day', within=['Store'])\n",
    "rm_results = rm_anova.fit()\n",
    "print(rm_results)\n",
    "\n",
    "# check if null hypothesis should be rejected based on p-value\n",
    "if rm_results.anova_table['Pr > F'][0] < 0.05:\n",
    "    # perform post-hoc Tukey test\n",
    "    print('Reject the Null Hypothesis : Atleast one of the group has different mean.\\n')\n",
    "    print('Tukey HSD posthoc test:')\n",
    "    tukey_results = pairwise_tukeyhsd(sales_melted['Sales'], sales_melted['Store'])\n",
    "    print(tukey_results)\n",
    "else:\n",
    "    print('NO significant difference between groups.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8017967e-5a22-49db-926a-bad4219a11c7",
   "metadata": {},
   "source": [
    "## Interpretation of the above - \n",
    "\n",
    "1. In Repeated Measure ANOVA test we got p_value (Pr>F) as 0.0000 which is less than 0.05 .Reject the Null Hypothesis .Which means atleast one of the mean of groups is different.\n",
    "\n",
    "2. In Tukey's Post Hoc Test we get following interpretation :\n",
    "\n",
    "- No significant difference between sales of Store A and Store B. Store B earns 21.24 dollars more than store A(becuse reject=False for this)\n",
    "- Significant difference between sales of Store A and Store C . Store C has approx 207.8 dollars lesser compared to store A (reject=True)\n",
    "- Siginficant difference between sales of Store B and Store C . Store C has approx 229.0 dollars lesser compared to store B (reject=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fe6306-80a8-4825-a000-e75c03105ed5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
